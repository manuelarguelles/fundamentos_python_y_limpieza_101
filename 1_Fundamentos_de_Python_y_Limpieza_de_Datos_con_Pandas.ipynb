{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK8u5gl6uGwGn813wUiHnx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelarguelles/fundamentos_python_y_limpieza_101/blob/main/1_Fundamentos_de_Python_y_Limpieza_de_Datos_con_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6OqD4rmJJ7X"
      },
      "outputs": [],
      "source": [
        "x = 5\n",
        "y = 6\n",
        "print (5+6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sesión 4.18: Fundamentos de Python y Limpieza de Datos con Pandas\n",
        "\n",
        "## Objetivos de la Sesión\n",
        "1. Configurar entorno con Jupyter Notebooks\n",
        "2. Aprender estructuras básicas de Pandas (Series y DataFrames)\n",
        "3. Cargar datos desde archivos CSV\n",
        "4. Realizar limpieza de datos: nulos, duplicados, tipos de datos\n",
        "5. Filtrar, ordenar y transformar datos\n",
        "6. Crear un pipeline completo de limpieza\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ttRWqiuaJunZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importación de Librerías\n",
        "\n",
        "Importamos las librerías necesarias para el análisis de datos."
      ],
      "metadata": {
        "id": "KJGKCHDdJzpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías principales\n",
        "import pandas as pd  # Para manipulación de datos\n",
        "import numpy as np   # Para operaciones numéricas\n",
        "\n",
        "# Configuración para mostrar más columnas y filas\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.max_rows', 100)      # Mostrar hasta 100 filas\n",
        "pd.set_option('display.width', None)        # Ancho automático\n",
        "\n",
        "# Verificar versiones\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ],
      "metadata": {
        "id": "xlpARdM-J19l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Pandas Series - Estructura Unidimensional\n",
        "\n",
        "Una **Series** es un array unidimensional con índices etiquetados."
      ],
      "metadata": {
        "id": "lQujVRO9J5a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una Series desde una lista\n",
        "ventas_enero = pd.Series([150000, 200000, 175000, 300000])\n",
        "print(\"Series con índices automáticos:\")\n",
        "print(ventas_enero)\n",
        "print(f\"\\nTipo: {type(ventas_enero)}\")"
      ],
      "metadata": {
        "id": "PZR52A1mJ7jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear Series con índices personalizados\n",
        "ventas_por_mes = pd.Series(\n",
        "    [150000, 200000, 175000, 300000],\n",
        "    index=['Enero', 'Febrero', 'Marzo', 'Abril']\n",
        ")\n",
        "print(\"Series con índices personalizados:\")\n",
        "print(ventas_por_mes)"
      ],
      "metadata": {
        "id": "c02V0I15KKdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear Series desde un diccionario\n",
        "precios_productos = pd.Series({\n",
        "    'Laptop': 1299.99,\n",
        "    'Mouse': 25.50,\n",
        "    'Teclado': 89.99,\n",
        "    'Monitor': 349.99\n",
        "})\n",
        "print(\"Series desde diccionario:\")\n",
        "print(precios_productos)"
      ],
      "metadata": {
        "id": "_N9N_coMKNgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Operaciones básicas con Series\n",
        "print(\"Operaciones con Series:\")\n",
        "print(f\"Suma total: ${ventas_por_mes.sum():,.2f}\")\n",
        "print(f\"Promedio: ${ventas_por_mes.mean():,.2f}\")\n",
        "print(f\"Máximo: ${ventas_por_mes.max():,.2f}\")\n",
        "print(f\"Mínimo: ${ventas_por_mes.min():,.2f}\")\n",
        "\n",
        "# Operaciones vectorizadas\n",
        "print(\"\\nIncrementar 10% todas las ventas:\")\n",
        "print(ventas_por_mes * 1.1)\n",
        "\n",
        "# Filtrado\n",
        "print(\"\\nMeses con ventas > 180,000:\")\n",
        "print(ventas_por_mes[ventas_por_mes > 180000])"
      ],
      "metadata": {
        "id": "JPw1fYMyKQl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Pandas DataFrames - Estructura Bidimensional\n",
        "\n",
        "Un **DataFrame** es una estructura bidimensional (tabla) con filas y columnas etiquetadas."
      ],
      "metadata": {
        "id": "QrMA5C3nKYGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame desde un diccionario\n",
        "ventas_df = pd.DataFrame({\n",
        "    'producto': ['Laptop', 'Mouse', 'Teclado', 'Monitor'],\n",
        "    'precio': [1299.99, 25.50, 89.99, 349.99],\n",
        "    'cantidad': [5, 50, 30, 10],\n",
        "    'categoria': ['Computadoras', 'Accesorios', 'Accesorios', 'Computadoras']\n",
        "})\n",
        "\n",
        "print(\"DataFrame de ventas:\")\n",
        "print(ventas_df)"
      ],
      "metadata": {
        "id": "f09So83wKaAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explorar la anatomía del DataFrame\n",
        "print(\"=== ANATOMÍA DEL DATAFRAME ===\\n\")\n",
        "\n",
        "# Dimensiones (filas, columnas)\n",
        "print(f\"Dimensiones (filas, columnas): {ventas_df.shape}\")\n",
        "\n",
        "# Nombres de columnas\n",
        "print(f\"\\nColumnas: {ventas_df.columns.tolist()}\")\n",
        "\n",
        "# Índices\n",
        "print(f\"\\nÍndices: {ventas_df.index.tolist()}\")\n",
        "\n",
        "# Tipos de datos\n",
        "print(\"\\nTipos de datos por columna:\")\n",
        "print(ventas_df.dtypes)"
      ],
      "metadata": {
        "id": "qKSk7THaKdel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métodos de inspección rápida\n",
        "print(\"=== INSPECCIÓN RÁPIDA ===\\n\")\n",
        "\n",
        "# Primeras filas\n",
        "print(\"Primeras 3 filas:\")\n",
        "print(ventas_df.head(3))\n",
        "\n",
        "# Últimas filas\n",
        "print(\"\\nÚltimas 2 filas:\")\n",
        "print(ventas_df.tail(2))"
      ],
      "metadata": {
        "id": "tJsY-_ohKfi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información general del DataFrame\n",
        "print(\"Información general del DataFrame:\")\n",
        "print(ventas_df.info())"
      ],
      "metadata": {
        "id": "OfDqhM8MKjHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas descriptivas\n",
        "print(\"Estadísticas descriptivas (solo columnas numéricas):\")\n",
        "print(ventas_df.describe())\n",
        "\n",
        "print(\"\\n\\nEstadísticas de todas las columnas:\")\n",
        "print(ventas_df.describe(include='all'))"
      ],
      "metadata": {
        "id": "EH_eIrABKlwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Selección de Datos en DataFrames\n",
        "\n",
        "Diferentes métodos para acceder y seleccionar datos."
      ],
      "metadata": {
        "id": "cvySaK9KKnhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de columnas\n",
        "print(\"=== SELECCIÓN DE COLUMNAS ===\\n\")\n",
        "\n",
        "# Una columna (retorna Series)\n",
        "print(\"Una columna (tipo Series):\")\n",
        "print(ventas_df['producto'])\n",
        "print(f\"Tipo: {type(ventas_df['producto'])}\")\n",
        "\n",
        "# Múltiples columnas (retorna DataFrame)\n",
        "print(\"\\n\\nMúltiples columnas (tipo DataFrame):\")\n",
        "print(ventas_df[['producto', 'precio']])\n",
        "print(f\"Tipo: {type(ventas_df[['producto', 'precio']])}\")"
      ],
      "metadata": {
        "id": "EzKB_E5_KqE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acceso con .loc[] (por etiquetas)\n",
        "print(\"=== ACCESO CON .loc[] ===\\n\")\n",
        "\n",
        "# Seleccionar una fila\n",
        "print(\"Fila con índice 0:\")\n",
        "print(ventas_df.loc[0])\n",
        "\n",
        "# Seleccionar rango de filas (inclusivo en ambos extremos)\n",
        "print(\"\\n\\nFilas 0 a 2 (inclusivo):\")\n",
        "print(ventas_df.loc[0:2])\n",
        "\n",
        "# Seleccionar filas y columnas específicas\n",
        "print(\"\\n\\nFilas 0-2, columnas 'producto' y 'precio':\")\n",
        "print(ventas_df.loc[0:2, ['producto', 'precio']])\n",
        "\n",
        "# Todas las filas, columnas específicas\n",
        "print(\"\\n\\nTodas las filas, columnas seleccionadas:\")\n",
        "print(ventas_df.loc[:, ['producto', 'cantidad']])"
      ],
      "metadata": {
        "id": "_vnoU1v9Kr9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acceso con .iloc[] (por posición numérica)\n",
        "print(\"=== ACCESO CON .iloc[] ===\\n\")\n",
        "\n",
        "# Primera fila\n",
        "print(\"Primera fila (posición 0):\")\n",
        "print(ventas_df.iloc[0])\n",
        "\n",
        "# Primeras 3 filas (exclusivo en límite superior)\n",
        "print(\"\\n\\nPrimeras 3 filas (0:3):\")\n",
        "print(ventas_df.iloc[0:3])\n",
        "\n",
        "# Todas las filas, primeras 2 columnas\n",
        "print(\"\\n\\nTodas las filas, primeras 2 columnas:\")\n",
        "print(ventas_df.iloc[:, 0:2])\n",
        "\n",
        "# Última fila\n",
        "print(\"\\n\\nÚltima fila:\")\n",
        "print(ventas_df.iloc[-1])"
      ],
      "metadata": {
        "id": "R1g1UnwtKuKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección booleana (filtrado)\n",
        "print(\"=== SELECCIÓN BOOLEANA ===\\n\")\n",
        "\n",
        "# Filtro simple\n",
        "print(\"Productos con precio > 100:\")\n",
        "print(ventas_df[ventas_df['precio'] > 100])\n",
        "\n",
        "# Múltiples condiciones con AND\n",
        "print(\"\\n\\nPrecio > 50 Y cantidad > 10:\")\n",
        "print(ventas_df[(ventas_df['precio'] > 50) & (ventas_df['cantidad'] > 10)])\n",
        "\n",
        "# Múltiples condiciones con OR\n",
        "print(\"\\n\\nCategoría Accesorios O precio < 100:\")\n",
        "print(ventas_df[(ventas_df['categoria'] == 'Accesorios') | (ventas_df['precio'] < 100)])\n",
        "\n",
        "# Filtro con .isin()\n",
        "categorias = ['Computadoras', 'Tablets']\n",
        "print(f\"\\n\\nProductos en categorías {categorias}:\")\n",
        "print(ventas_df[ventas_df['categoria'].isin(categorias)])"
      ],
      "metadata": {
        "id": "3z8drjz1Kvqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Carga de Datos desde CSV\n",
        "\n",
        "Ahora vamos a cargar el dataset real con problemas típicos de datos sucios."
      ],
      "metadata": {
        "id": "GhVEoBB6KzoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo CSV con datos crudos\n",
        "# NOTA: Asegurarse de que el archivo 'ventas_raw.csv' esté en el mismo directorio\n",
        "\n",
        "df_raw = pd.read_csv('ventas_raw.csv')\n",
        "\n",
        "print(\"=== DATOS CARGADOS (RAW) ===\")\n",
        "print(f\"Dimensiones: {df_raw.shape}\")\n",
        "print(f\"\\nPrimeras 10 filas:\")\n",
        "print(df_raw.head(10))"
      ],
      "metadata": {
        "id": "xN8uTPFAKxql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploración inicial del dataset crudo\n",
        "print(\"=== EXPLORACIÓN INICIAL ===\\n\")\n",
        "print(df_raw.info())"
      ],
      "metadata": {
        "id": "PM2lmYukLmml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas descriptivas del dataset crudo\n",
        "print(\"Estadísticas descriptivas:\")\n",
        "print(df_raw.describe(include='all'))"
      ],
      "metadata": {
        "id": "9t8ADH1mLqBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas descriptivas del dataset crudo\n",
        "print(\"Estadísticas descriptivas:\")\n",
        "print(df_raw.describe(include='all'))"
      ],
      "metadata": {
        "id": "LzvKQ3WHLu6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Detección de Problemas en los Datos\n",
        "\n",
        "Identificamos todos los problemas presentes en el dataset."
      ],
      "metadata": {
        "id": "nT_VmrPiLxOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Detectar valores nulos\n",
        "print(\"=== DETECCIÓN DE VALORES NULOS ===\\n\")\n",
        "print(\"Nulos por columna:\")\n",
        "print(df_raw.isnull().sum())\n",
        "\n",
        "print(f\"\\nTotal de valores nulos: {df_raw.isnull().sum().sum()}\")\n",
        "print(f\"Porcentaje de nulos por columna:\")\n",
        "print((df_raw.isnull().sum() / len(df_raw)) * 100)"
      ],
      "metadata": {
        "id": "HqsQBdhFLwoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver filas con valores nulos\n",
        "print(\"Filas que contienen valores nulos:\")\n",
        "print(df_raw[df_raw.isnull().any(axis=1)])"
      ],
      "metadata": {
        "id": "HEVM4HfTL9-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Detectar duplicados\n",
        "print(\"=== DETECCIÓN DE DUPLICADOS ===\\n\")\n",
        "print(f\"Total de filas duplicadas: {df_raw.duplicated().sum()}\")\n",
        "\n",
        "# Ver las filas duplicadas\n",
        "print(\"\\nFilas duplicadas:\")\n",
        "print(df_raw[df_raw.duplicated(keep=False)])"
      ],
      "metadata": {
        "id": "q19HDSXXMAJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Inspeccionar tipos de datos incorrectos\n",
        "print(\"=== PROBLEMAS EN TIPOS DE DATOS ===\\n\")\n",
        "print(\"Tipos actuales:\")\n",
        "print(df_raw.dtypes)\n",
        "\n",
        "print(\"\\n⚠️ Problemas identificados:\")\n",
        "print(\"- 'fecha_venta' es object, debería ser datetime\")\n",
        "print(\"- 'precio' es object (contiene símbolos $), debería ser float\")\n",
        "print(\"- 'cantidad' es object, debería ser int\")"
      ],
      "metadata": {
        "id": "LwGt2BSXMHBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Ver valores únicos en columnas categóricas\n",
        "print(\"=== VALORES ÚNICOS EN CATEGORÍAS ===\\n\")\n",
        "\n",
        "print(\"Categorías únicas (problema de mayúsculas/minúsculas):\")\n",
        "print(df_raw['categoria'].unique())\n",
        "\n",
        "print(\"\\nRegiones únicas:\")\n",
        "print(df_raw['region'].unique())"
      ],
      "metadata": {
        "id": "roPDhQJOMIhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Detectar valores fuera de rango\n",
        "print(\"=== VALORES FUERA DE RANGO ===\\n\")\n",
        "\n",
        "# Intentar convertir cantidad a numérico para ver problemas\n",
        "df_raw['cantidad_temp'] = pd.to_numeric(df_raw['cantidad'], errors='coerce')\n",
        "\n",
        "print(\"Estadísticas de cantidad (después de conversión):\")\n",
        "print(df_raw['cantidad_temp'].describe())\n",
        "\n",
        "print(\"\\n⚠️ Cantidades negativas o cero:\")\n",
        "print(df_raw[df_raw['cantidad_temp'] <= 0][['transaccion_id', 'producto', 'cantidad_temp']])\n",
        "\n",
        "# Eliminar columna temporal\n",
        "df_raw.drop('cantidad_temp', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "uD1PYC0zMK2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Pipeline de Limpieza de Datos\n",
        "\n",
        "Ahora aplicamos un proceso sistemático de limpieza paso a paso."
      ],
      "metadata": {
        "id": "QTMnZmvQMNwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una copia para trabajar sin modificar los datos originales\n",
        "df = df_raw.copy()\n",
        "\n",
        "print(\"=== INICIO DEL PROCESO DE LIMPIEZA ===\")\n",
        "print(f\"Registros iniciales: {len(df)}\")\n",
        "print(f\"Columnas: {len(df.columns)}\")"
      ],
      "metadata": {
        "id": "Bylzq9cPMNIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1: Limpieza de Duplicados"
      ],
      "metadata": {
        "id": "PK-8dVF1MRtO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "230c46eb"
      },
      "source": [
        "# Eliminar duplicados completos\n",
        "print(\"PASO 1: Eliminación de duplicados\")\n",
        "print(f\"Duplicados encontrados: {df.duplicated().sum()}\")\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(f\"Registros después de eliminar duplicados: {len(df)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2: Limpieza y Conversión de Fechas"
      ],
      "metadata": {
        "id": "4FdP-J8mNHcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir fechas (múltiples formatos)\n",
        "print(\"PASO 2: Conversión de fechas\")\n",
        "\n",
        "# Ver formatos actuales\n",
        "print(\"Muestra de fechas antes de convertir:\")\n",
        "print(df['fecha_venta'].head(10))\n",
        "\n",
        "# Convertir con inferencia automática\n",
        "df['fecha_venta'] = pd.to_datetime(df['fecha_venta'], errors='coerce')\n",
        "\n",
        "# Ver resultado\n",
        "print(\"\\nDespués de conversión:\")\n",
        "print(df['fecha_venta'].head(10))\n",
        "print(f\"Tipo de datos: {df['fecha_venta'].dtype}\")\n",
        "\n",
        "# Ver si hay fechas que no pudieron convertirse (NaT)\n",
        "print(f\"\\nFechas nulas (NaT) después de conversión: {df['fecha_venta'].isna().sum()}\")"
      ],
      "metadata": {
        "id": "VjLYxE8bNJS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver filas con fechas nulas\n",
        "print(\"Registros con fecha nula:\")\n",
        "print(df[df['fecha_venta'].isna()][['transaccion_id', 'fecha_venta', 'producto']])"
      ],
      "metadata": {
        "id": "QH6NDiLHNM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3: Limpieza y Conversión de Precios"
      ],
      "metadata": {
        "id": "qUFCA9SYNhMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar y convertir precios\n",
        "print(\"PASO 3: Limpieza de precios\")\n",
        "\n",
        "# Ver valores actuales\n",
        "print(\"Muestra de precios antes de limpiar:\")\n",
        "print(df['precio'].head(10))\n",
        "\n",
        "# Eliminar símbolos y convertir\n",
        "df['precio'] = df['precio'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
        "df['precio'] = pd.to_numeric(df['precio'], errors='coerce')\n",
        "\n",
        "print(\"\\nDespués de limpieza:\")\n",
        "print(df['precio'].head(10))\n",
        "print(f\"Tipo de datos: {df['precio'].dtype}\")\n",
        "\n",
        "# Estadísticas\n",
        "print(\"\\nEstadísticas de precios:\")\n",
        "print(df['precio'].describe())\n",
        "\n",
        "# Ver precios nulos\n",
        "print(f\"\\nPrecios nulos: {df['precio'].isna().sum()}\")"
      ],
      "metadata": {
        "id": "xdYZg7SzNjLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4: Conversión de Cantidades"
      ],
      "metadata": {
        "id": "VSpqq5uHNlk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir cantidades a enteros\n",
        "print(\"PASO 4: Conversión de cantidades\")\n",
        "\n",
        "# Convertir\n",
        "df['cantidad'] = pd.to_numeric(df['cantidad'], errors='coerce')\n",
        "\n",
        "print(f\"Tipo de datos: {df['cantidad'].dtype}\")\n",
        "print(\"\\nEstadísticas:\")\n",
        "print(df['cantidad'].describe())\n",
        "\n",
        "# Identificar cantidades problemáticas\n",
        "print(\"\\nCantidades nulas o <= 0:\")\n",
        "print(df[(df['cantidad'].isna()) | (df['cantidad'] <= 0)][['transaccion_id', 'producto', 'cantidad']])"
      ],
      "metadata": {
        "id": "8Cq-FRaiNnia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 5: Manejo de Valores Nulos"
      ],
      "metadata": {
        "id": "1xuQDuXiNsCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrategia de manejo de nulos\n",
        "print(\"PASO 5: Manejo de valores nulos\")\n",
        "\n",
        "print(\"\\nResumen de nulos antes de tratamiento:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Estrategia por columna:\n",
        "# - fecha_venta: eliminar filas (crítico para análisis temporal)\n",
        "# - precio: eliminar filas (crítico para cálculos)\n",
        "# - cantidad: imputar con 1 (asumimos una unidad)\n",
        "# - descuento: imputar con 0 (sin descuento)\n",
        "\n",
        "# Eliminar filas con fecha o precio nulo\n",
        "registros_antes = len(df)\n",
        "df = df.dropna(subset=['fecha_venta', 'precio'])\n",
        "registros_despues = len(df)\n",
        "\n",
        "print(f\"\\nFilas eliminadas por fecha/precio nulo: {registros_antes - registros_despues}\")\n",
        "\n",
        "# Imputar cantidad nula con 1\n",
        "df['cantidad'].fillna(1, inplace=True)\n",
        "\n",
        "# Imputar descuento nulo con 0\n",
        "df['descuento'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"\\nResumen de nulos después de tratamiento:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "li2o2FvzNpIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 6: Normalización de Texto"
      ],
      "metadata": {
        "id": "BpN_0iaINwQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar strings\n",
        "print(\"PASO 6: Normalización de texto\")\n",
        "\n",
        "# Eliminar espacios extras en todas las columnas de texto\n",
        "columnas_texto = ['transaccion_id', 'producto', 'categoria', 'cliente', 'region']\n",
        "\n",
        "for col in columnas_texto:\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "# Normalizar categorías a Title Case\n",
        "print(\"\\nCategorías antes:\")\n",
        "print(df['categoria'].unique())\n",
        "\n",
        "df['categoria'] = df['categoria'].str.title()\n",
        "\n",
        "print(\"\\nCategorías después:\")\n",
        "print(df['categoria'].unique())\n",
        "\n",
        "# Normalizar regiones\n",
        "df['region'] = df['region'].str.title()\n",
        "\n",
        "print(\"\\nRegiones únicas:\")\n",
        "print(df['region'].unique())"
      ],
      "metadata": {
        "id": "IcFGiTYGNzMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 7: Filtrado de Valores Válidos"
      ],
      "metadata": {
        "id": "l_anreUDN1zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar registros válidos\n",
        "print(\"PASO 7: Filtrado de valores válidos\")\n",
        "\n",
        "registros_antes = len(df)\n",
        "\n",
        "# Filtrar: precio > 0, cantidad > 0, descuento entre 0 y 1\n",
        "df = df[\n",
        "    (df['precio'] > 0) &\n",
        "    (df['cantidad'] > 0) &\n",
        "    (df['descuento'] >= 0) &\n",
        "    (df['descuento'] <= 1)\n",
        "]\n",
        "\n",
        "registros_despues = len(df)\n",
        "\n",
        "print(f\"Registros eliminados por valores inválidos: {registros_antes - registros_despues}\")\n",
        "print(f\"Registros válidos restantes: {registros_despues}\")"
      ],
      "metadata": {
        "id": "IDh2bzylN1AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 8: Conversión Final de Tipos de Datos"
      ],
      "metadata": {
        "id": "lAIcdHsHN_yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurar tipos correctos\n",
        "print(\"PASO 8: Conversión final de tipos\")\n",
        "\n",
        "# Convertir cantidad a int (ya es float después de fillna)\n",
        "df['cantidad'] = df['cantidad'].astype(int)\n",
        "\n",
        "# IDs como string\n",
        "df['transaccion_id'] = df['transaccion_id'].astype(str)\n",
        "df['producto_id'] = df['producto_id'].astype(str)\n",
        "df['cliente_id'] = df['cliente_id'].astype(str)\n",
        "\n",
        "print(\"Tipos de datos finales:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "qupall7tOBep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 9: Creación de Columnas Calculadas"
      ],
      "metadata": {
        "id": "KUiV6eexPI-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear columnas derivadas\n",
        "print(\"PASO 9: Creación de columnas calculadas\")\n",
        "\n",
        "# Calcular total de venta\n",
        "df['total'] = df['cantidad'] * df['precio']\n",
        "\n",
        "# Calcular precio final con descuento\n",
        "df['precio_final'] = df['precio'] * (1 - df['descuento'])\n",
        "\n",
        "# Calcular total final\n",
        "df['total_final'] = df['cantidad'] * df['precio_final']\n",
        "\n",
        "# Extraer componentes de fecha\n",
        "df['año'] = df['fecha_venta'].dt.year\n",
        "df['mes'] = df['fecha_venta'].dt.month\n",
        "df['dia'] = df['fecha_venta'].dt.day\n",
        "df['dia_semana'] = df['fecha_venta'].dt.day_name()\n",
        "\n",
        "# Crear período año-mes\n",
        "df['año_mes'] = df['fecha_venta'].dt.to_period('M')\n",
        "\n",
        "print(\"Columnas añadidas:\")\n",
        "print(df[['transaccion_id', 'total', 'precio_final', 'total_final', 'año', 'mes']].head())"
      ],
      "metadata": {
        "id": "Rm2xTnf2PK_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 10: Ordenamiento y Reset de Índice"
      ],
      "metadata": {
        "id": "3TS5h19cPMf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar por fecha y resetear índice\n",
        "print(\"PASO 10: Ordenamiento final\")\n",
        "\n",
        "df = df.sort_values('fecha_venta').reset_index(drop=True)\n",
        "\n",
        "print(\"Primeras filas después de ordenar:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "U4ecA2EkPN7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Validaciones Post-Limpieza\n",
        "\n",
        "Verificamos que los datos estén correctos y completos."
      ],
      "metadata": {
        "id": "Cp0BvUxgPP-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validaciones finales\n",
        "print(\"=== VALIDACIONES POST-LIMPIEZA ===\\n\")\n",
        "\n",
        "# 1. Verificar que no hay nulos en columnas críticas\n",
        "columnas_criticas = ['transaccion_id', 'fecha_venta', 'producto', 'precio', 'cantidad']\n",
        "nulos_criticos = df[columnas_criticas].isnull().sum().sum()\n",
        "\n",
        "print(f\"1. Nulos en columnas críticas: {nulos_criticos}\")\n",
        "assert nulos_criticos == 0, \"⚠️ Aún hay nulos en columnas críticas\"\n",
        "print(\"   ✓ No hay nulos en columnas críticas\")\n",
        "\n",
        "# 2. Verificar tipos de datos\n",
        "print(\"\\n2. Verificación de tipos de datos:\")\n",
        "assert df['fecha_venta'].dtype == 'datetime64[ns]', \"Fecha no es datetime\"\n",
        "print(\"   ✓ Fechas en formato datetime\")\n",
        "\n",
        "assert df['precio'].dtype in ['float64', 'float32'], \"Precio no es float\"\n",
        "print(\"   ✓ Precios en formato numérico\")\n",
        "\n",
        "assert df['cantidad'].dtype in ['int64', 'int32'], \"Cantidad no es int\"\n",
        "print(\"   ✓ Cantidades en formato entero\")\n",
        "\n",
        "# 3. Verificar rangos válidos\n",
        "print(\"\\n3. Verificación de rangos:\")\n",
        "assert (df['precio'] > 0).all(), \"Hay precios <= 0\"\n",
        "print(\"   ✓ Todos los precios son positivos\")\n",
        "\n",
        "assert (df['cantidad'] > 0).all(), \"Hay cantidades <= 0\"\n",
        "print(\"   ✓ Todas las cantidades son positivas\")\n",
        "\n",
        "assert (df['descuento'] >= 0).all() and (df['descuento'] <= 1).all(), \"Descuentos fuera de rango\"\n",
        "print(\"   ✓ Descuentos entre 0 y 1\")\n",
        "\n",
        "# 4. Verificar que no hay duplicados\n",
        "print(f\"\\n4. Duplicados: {df.duplicated().sum()}\")\n",
        "assert df.duplicated().sum() == 0, \"Hay duplicados\"\n",
        "print(\"   ✓ No hay registros duplicados\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✅ TODAS LAS VALIDACIONES PASARON CORRECTAMENTE\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "dIyT_-IFPPuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 9. Resumen Final y Comparación"
      ],
      "metadata": {
        "id": "Qknn5RQIPZAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparación antes vs después\n",
        "print(\"=== COMPARACIÓN: DATOS CRUDOS VS DATOS LIMPIOS ===\\n\")\n",
        "\n",
        "print(f\"Registros originales:    {len(df_raw)}\")\n",
        "print(f\"Registros limpios:       {len(df)}\")\n",
        "print(f\"Registros eliminados:    {len(df_raw) - len(df)}\")\n",
        "print(f\"Porcentaje retenido:     {(len(df) / len(df_raw)) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nColumnas originales:     {len(df_raw.columns)}\")\n",
        "print(f\"Columnas finales:        {len(df.columns)}\")\n",
        "print(f\"Columnas añadidas:       {len(df.columns) - len(df_raw.columns)}\")\n",
        "\n",
        "print(f\"\\nMemoria original:        {df_raw.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "print(f\"Memoria final:           {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
      ],
      "metadata": {
        "id": "bq7b0xZ6PYj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vista final del dataset limpio\n",
        "print(\"=== DATASET LIMPIO - PRIMERAS 10 FILAS ===\")\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "PW_r-4JbPcEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información final del dataset\n",
        "print(\"=== INFORMACIÓN FINAL DEL DATASET ===\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "ZH6L1EDXPeSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 10. Análisis Exploratorio Básico\n",
        "\n",
        "Ahora que tenemos datos limpios, podemos hacer análisis básico."
      ],
      "metadata": {
        "id": "mmLLJLOQPhgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis por categoría\n",
        "print(\"=== VENTAS POR CATEGORÍA ===\\n\")\n",
        "\n",
        "ventas_categoria = df.groupby('categoria').agg({\n",
        "    'total_final': 'sum',\n",
        "    'cantidad': 'sum',\n",
        "    'transaccion_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "ventas_categoria.columns = ['Ventas Totales', 'Unidades Vendidas', 'Num Transacciones']\n",
        "ventas_categoria = ventas_categoria.sort_values('Ventas Totales', ascending=False)\n",
        "\n",
        "print(ventas_categoria)"
      ],
      "metadata": {
        "id": "f7eFM7X3PhHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis por región\n",
        "print(\"=== VENTAS POR REGIÓN ===\\n\")\n",
        "\n",
        "ventas_region = df.groupby('region').agg({\n",
        "    'total_final': ['sum', 'mean'],\n",
        "    'transaccion_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "ventas_region.columns = ['Total Ventas', 'Ticket Promedio', 'Num Transacciones']\n",
        "ventas_region = ventas_region.sort_values('Total Ventas', ascending=False)\n",
        "\n",
        "print(ventas_region)"
      ],
      "metadata": {
        "id": "oEBqmfS8PzfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 productos más vendidos\n",
        "print(\"=== TOP 10 PRODUCTOS MÁS VENDIDOS ===\\n\")\n",
        "\n",
        "top_productos = df.groupby('producto').agg({\n",
        "    'cantidad': 'sum',\n",
        "    'total_final': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "top_productos.columns = ['Unidades', 'Ventas Totales']\n",
        "top_productos = top_productos.sort_values('Ventas Totales', ascending=False).head(10)\n",
        "\n",
        "print(top_productos)"
      ],
      "metadata": {
        "id": "xuR5f6cMRIgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis temporal\n",
        "print(\"=== VENTAS POR MES ===\\n\")\n",
        "\n",
        "ventas_mes = df.groupby('año_mes').agg({\n",
        "    'total_final': 'sum',\n",
        "    'transaccion_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "ventas_mes.columns = ['Ventas Totales', 'Num Transacciones']\n",
        "\n",
        "print(ventas_mes)"
      ],
      "metadata": {
        "id": "LITi4_TURKPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 11. Exportar Datos Limpios\n",
        "\n",
        "Guardamos el dataset limpio para uso futuro."
      ],
      "metadata": {
        "id": "-RWP2o_dRM3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar datos limpios\n",
        "nombre_archivo = 'ventas_clean.csv'\n",
        "df.to_csv(nombre_archivo, index=False)\n",
        "\n",
        "print(f\"✅ Datos limpios guardados en: {nombre_archivo}\")\n",
        "print(f\"   Registros: {len(df)}\")\n",
        "print(f\"   Columnas: {len(df.columns)}\")"
      ],
      "metadata": {
        "id": "qIguwzF8RLsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 12. Resumen de Aprendizajes\n",
        "\n",
        "### Conceptos Cubiertos:\n",
        "1. ✓ Jupyter Notebooks y entorno de trabajo\n",
        "2. ✓ Pandas Series y DataFrames\n",
        "3. ✓ Carga de datos desde CSV\n",
        "4. ✓ Selección y filtrado de datos (`.loc[]`, `.iloc[]`, booleanos)\n",
        "5. ✓ Detección de problemas (nulos, duplicados, tipos incorrectos)\n",
        "6. ✓ Limpieza de datos sistemática\n",
        "7. ✓ Conversión de tipos de datos\n",
        "8. ✓ Creación de columnas calculadas\n",
        "9. ✓ Validaciones de calidad de datos\n",
        "10. ✓ Análisis exploratorio básico\n",
        "\n",
        "### Próximos Pasos:\n",
        "- Sesión 4.19: Funciones avanzadas (apply, map, groupby) e ingesta a PostgreSQL\n",
        "- Agregar visualizaciones con Matplotlib/Seaborn\n",
        "- Automatizar el pipeline de limpieza"
      ],
      "metadata": {
        "id": "E4liWGu7RTVt"
      }
    }
  ]
}